{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions from other papers:\n",
    "\n",
    "Adaptive - Cao et al. 2020.\n",
    "Equalised - Tan et al. 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Start by writing custom loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairwiseMarginLoss(nn.Module):\n",
    "    def __init__(self, delta):\n",
    "        super(PairwiseMarginLoss, self).__init__()\n",
    "        self.delta = torch.tensor(delta, device=device)\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        loss = torch.tensor([0], device=device)\n",
    "        for i in range(N):\n",
    "            loss_i = torch.nn.functional.log_softmax(outputs[i] + self.delta[targets[i]])[targets[i]]\n",
    "            loss = loss - loss_i\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTan = [[np.log(class_prob[yp]) * (yp != y) for yp in range(len(class_prob))] for y in range(len(class_prob))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bin_tan = LinearClassifier()\n",
    "model_bin_tan.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_bin_tan = torch.optim.Adam(model_bin_tan.parameters())\n",
    "criterion_bin_tan = PairwiseMarginLoss(deltaTan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_loss_bin_tan = []\n",
    "for epoch in range(1000):\n",
    "\n",
    "    # zero the gradients\n",
    "    optimizer_bin_tan.zero_grad()\n",
    "\n",
    "    # forward\n",
    "    output_bin_tan = model_bin_tan(X_train)\n",
    "    loss_bin_tan = criterion_bin_tan(output_bin_tan, y_train.view(-1))\n",
    "\n",
    "    # backward\n",
    "    all_loss_bin_tan.append(loss_bin_tan.item())\n",
    "    loss_bin_tan.backward()\n",
    "\n",
    "    # optimize\n",
    "    optimizer_bin_tan.step()\n",
    "\n",
    "    print(f\"Loss at epoch {epoch}: {loss_bin_tan.item()}\")\n",
    "\n",
    "plt.plot(all_loss_bin_tan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0_tan = model_bin_tan.linear.weight[0].detach().cpu().numpy()\n",
    "w1_tan = model_bin_tan.linear.weight[1].detach().cpu().numpy()\n",
    "b0_tan = model_bin_tan.linear.bias[0].detach().cpu().numpy()\n",
    "b1_tan = model_bin_tan.linear.bias[1].detach().cpu().numpy()\n",
    "\n",
    "plt.xlim([-4, 4])\n",
    "plt.ylim([-4, 4])\n",
    "plt.plot(sampA[:,0], sampA[:,1], 'cx')\n",
    "plt.plot(sampB[:,0], sampB[:,1], '.y')\n",
    "plot_db(w0_tan, w1_tan, b0_tan, b1_tan, modelType='Tan loss', lins='g')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Decision boundaries')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltaTan = [[np.log(class_prob[yp]) * (yp != y) for yp in range(len(class_prob))] for y in range(len(class_prob))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bin_tan = LinearClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_bin_tan = torch.optim.Adam(model_bin_tan.parameters())\n",
    "criterion_bin_tan = PairwiseMarginLoss(deltaTan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_loss_bin_tan = []\n",
    "for epoch in range(1000):\n",
    "\n",
    "    # zero the gradients\n",
    "    optimizer_bin_tan.zero_grad()\n",
    "\n",
    "    # forward\n",
    "    output_bin_tan = model_bin_tan(X_train)\n",
    "    loss_bin_tan = criterion_bin_tan(output_bin_tan, y_train.view(-1))\n",
    "\n",
    "    # backward\n",
    "    all_loss_bin_tan.append(loss_bin_tan.item())\n",
    "    loss_bin_tan.backward()\n",
    "\n",
    "    # optimize\n",
    "    optimizer_bin_tan.step()\n",
    "\n",
    "    print(f'{epoch}th: Loss is {loss_bin_tan}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0_tan = model_bin_tan.linear.weight[0].detach().numpy()\n",
    "w1_tan = model_bin_tan.linear.weight[1].detach().numpy()\n",
    "b0_tan = model_bin_tan.linear.bias[0].detach().numpy()\n",
    "b1_tan = model_bin_tan.linear.bias[1].detach().numpy()\n",
    "\n",
    "plt.xlim([-4, 4])\n",
    "plt.ylim([-4, 4])\n",
    "plt.plot(sampA[:,0], sampA[:,1], 'cx')\n",
    "plt.plot(sampB[:,0], sampB[:,1], '.y')\n",
    "plot_db(w0_tan, w1_tan, b0_tan, b1_tan, modelType='Tan loss', lins='g')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Decision boundaries')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b88f3570d76782ab2e008d1f0d592e086c2435fa4d15105de8c58386c13a6bdd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
