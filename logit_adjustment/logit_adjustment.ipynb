{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "\n",
    "from utils import download_tfrecord\n",
    "from tensorflow import make_ndarray\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "from tensorboard.backend.event_processing.tag_types import TENSORS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch a TensorBoard Session in VS Code or...\n",
    "\n",
    "Run the below (you may have to run the second command twice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or use\n",
    "\n",
    "```\n",
    "!tensorboard --logdir log\n",
    "```\n",
    "if the above doesn't work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "Run the below cells to download the CIFAR-10 datasets (or the CIFAR-100 ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_tfrecord(\"test10\", \"train10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training (and evaluation)\n",
    "\n",
    "Use ```main.py``` to train on the imbalanced version of CIFAR 10. This is to get the results in Table 1.\n",
    "\n",
    "Call it with the following flags/parameters:\n",
    "\n",
    "* ```dataset```: ```cifar10-lt``` (for CIFAR 10)\n",
    "* ```mode```: ```baseline```, ```posthoc``` or ```loss```\n",
    "    * whether to use baseline (vanilla) ERM\n",
    "    * or posthoc modification of logits\n",
    "    * or adjusted loss function\n",
    "\n",
    "The results can be found in Tensorboard: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vanilla ERM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --dataset=cifar10-lt --mode=baseline --tb_log_dir=log/ERM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posthoc update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --dataset=cifar10-lt --mode=posthoc --tb_log_dir=log/Additive_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logit adjusted loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --dataset=cifar10-lt --mode=loss --tb_log_dir=log/LA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the results\n",
    "\n",
    "* For Figure 1 and Table 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the class probabilities\n",
    "\n",
    "# Define the file path\n",
    "file_path = \"./data/cifar10-lt_base_probs.txt\"\n",
    "\n",
    "# Initialize a list to store the numbers\n",
    "class_prob = []\n",
    "\n",
    "# Open the file and read it line by line\n",
    "with open(file_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        # Remove leading/trailing whitespace and convert the line to a float\n",
    "        number = float(line.strip())\n",
    "        class_prob.append(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of samples in the training data. possible values for β\n",
    "\n",
    "N = 10000\n",
    "βs = [1, 0.999, 0.99, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate effective class frequency with formula in terms of β and empirical class frequency\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"class_num\": list(range(1, 10 + 1)) * len(βs),\n",
    "        \"class_prob\": class_prob * len(βs),\n",
    "        \"β\": sum([[β] * 10 for β in βs], start=[]),\n",
    "    }\n",
    ")\n",
    "\n",
    "df[\"effective_class_frequency\"] = (1 - df[\"β\"] ** (N * df[\"class_prob\"])) / (\n",
    "    1 - df[\"β\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise effective class frequency to get effective class probability\n",
    "\n",
    "df[\"effective_class_frequency\"] = df[\"effective_class_frequency\"] / df.groupby(\"β\")[\n",
    "    \"effective_class_frequency\"\n",
    "].transform(\"sum\")\n",
    "\n",
    "# when β = 1, use empirical class probability\n",
    "\n",
    "df[\"effective_class_frequency\"] = np.where(\n",
    "    df[\"effective_class_frequency\"].isna(),\n",
    "    df[\"class_prob\"],\n",
    "    df[\"effective_class_frequency\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-ed752e503fd74add973f239ea006ab1d.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-ed752e503fd74add973f239ea006ab1d.vega-embed details,\n",
       "  #altair-viz-ed752e503fd74add973f239ea006ab1d.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-ed752e503fd74add973f239ea006ab1d\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-ed752e503fd74add973f239ea006ab1d\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-ed752e503fd74add973f239ea006ab1d\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.15.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.15.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-e8b687606ce27f226e5c2e3fbf0e0309\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"\\u03b2\", \"sort\": [1, 0.999, 0.99, 0], \"type\": \"nominal\"}, \"column\": {\"field\": \"class_num\", \"title\": \"Classes (ranked by frequency)\", \"type\": \"ordinal\"}, \"x\": {\"axis\": {\"labels\": false, \"ticks\": false}, \"field\": \"\\u03b2\", \"sort\": [1, 0.999, 0.99, 0], \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"effective_class_frequency\", \"title\": \"Smoothed class probability\", \"type\": \"quantitative\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.15.1.json\", \"datasets\": {\"data-e8b687606ce27f226e5c2e3fbf0e0309\": [{\"class_num\": 1, \"class_prob\": 0.4030307915524746, \"\\u03b2\": 1.0, \"effective_class_frequency\": 0.4030307915524746}, {\"class_num\": 2, \"class_prob\": 0.24157665645655327, \"\\u03b2\": 1.0, \"effective_class_frequency\": 0.24157665645655327}, {\"class_num\": 3, \"class_prob\": 0.1447686603256489, \"\\u03b2\": 1.0, \"effective_class_frequency\": 0.1447686603256489}, {\"class_num\": 4, \"class_prob\": 0.08681283250040303, \"\\u03b2\": 1.0, \"effective_class_frequency\": 0.08681283250040303}, {\"class_num\": 5, \"class_prob\": 0.05199097211026923, \"\\u03b2\": 1.0, \"effective_class_frequency\": 0.05199097211026923}, {\"class_num\": 6, \"class_prob\": 0.031194583266161535, \"\\u03b2\": 1.0, \"effective_class_frequency\": 0.031194583266161535}, {\"class_num\": 7, \"class_prob\": 0.01870062872803482, \"\\u03b2\": 1.0, \"effective_class_frequency\": 0.01870062872803482}, {\"class_num\": 8, \"class_prob\": 0.011204256005158795, \"\\u03b2\": 1.0, \"effective_class_frequency\": 0.011204256005158795}, {\"class_num\": 9, \"class_prob\": 0.006690311139771078, \"\\u03b2\": 1.0, \"effective_class_frequency\": 0.006690311139771078}, {\"class_num\": 10, \"class_prob\": 0.004030307915524746, \"\\u03b2\": 1.0, \"effective_class_frequency\": 0.004030307915524746}, {\"class_num\": 1, \"class_prob\": 0.4030307915524746, \"\\u03b2\": 0.999, \"effective_class_frequency\": 0.22879590775919822}, {\"class_num\": 2, \"class_prob\": 0.24157665645655327, \"\\u03b2\": 0.999, \"effective_class_frequency\": 0.21215146962652995}, {\"class_num\": 3, \"class_prob\": 0.1447686603256489, \"\\u03b2\": 0.999, \"effective_class_frequency\": 0.17820190010823672}, {\"class_num\": 4, \"class_prob\": 0.08681283250040303, \"\\u03b2\": 0.999, \"effective_class_frequency\": 0.13520116591423798}, {\"class_num\": 5, \"class_prob\": 0.05199097211026923, \"\\u03b2\": 0.999, \"effective_class_frequency\": 0.0944703903008276}, {\"class_num\": 6, \"class_prob\": 0.031194583266161535, \"\\u03b2\": 0.999, \"effective_class_frequency\": 0.06244595396669319}, {\"class_num\": 7, \"class_prob\": 0.01870062872803482, \"\\u03b2\": 0.999, \"effective_class_frequency\": 0.039746348107799694}, {\"class_num\": 8, \"class_prob\": 0.011204256005158795, \"\\u03b2\": 0.999, \"effective_class_frequency\": 0.024700426328076234}, {\"class_num\": 9, \"class_prob\": 0.006690311139771078, \"\\u03b2\": 0.999, \"effective_class_frequency\": 0.015080934696993698}, {\"class_num\": 10, \"class_prob\": 0.004030307915524746, \"\\u03b2\": 0.999, \"effective_class_frequency\": 0.00920550319140681}, {\"class_num\": 1, \"class_prob\": 0.4030307915524746, \"\\u03b2\": 0.99, \"effective_class_frequency\": 0.12053175601959379}, {\"class_num\": 2, \"class_prob\": 0.24157665645655327, \"\\u03b2\": 0.99, \"effective_class_frequency\": 0.12053175601615225}, {\"class_num\": 3, \"class_prob\": 0.1447686603256489, \"\\u03b2\": 0.99, \"effective_class_frequency\": 0.12053169817920853}, {\"class_num\": 4, \"class_prob\": 0.08681283250040303, \"\\u03b2\": 0.99, \"effective_class_frequency\": 0.12051217252101477}, {\"class_num\": 5, \"class_prob\": 0.05199097211026923, \"\\u03b2\": 0.99, \"effective_class_frequency\": 0.11988342511448528}, {\"class_num\": 6, \"class_prob\": 0.031194583266161535, \"\\u03b2\": 0.99, \"effective_class_frequency\": 0.11528949515863893}, {\"class_num\": 7, \"class_prob\": 0.01870062872803482, \"\\u03b2\": 0.99, \"effective_class_frequency\": 0.10213016259993841}, {\"class_num\": 8, \"class_prob\": 0.011204256005158795, \"\\u03b2\": 0.99, \"effective_class_frequency\": 0.08144249030137297}, {\"class_num\": 9, \"class_prob\": 0.006690311139771078, \"\\u03b2\": 0.99, \"effective_class_frequency\": 0.05900239262413659}, {\"class_num\": 10, \"class_prob\": 0.004030307915524746, \"\\u03b2\": 0.99, \"effective_class_frequency\": 0.040144651465458425}, {\"class_num\": 1, \"class_prob\": 0.4030307915524746, \"\\u03b2\": 0.0, \"effective_class_frequency\": 0.1}, {\"class_num\": 2, \"class_prob\": 0.24157665645655327, \"\\u03b2\": 0.0, \"effective_class_frequency\": 0.1}, {\"class_num\": 3, \"class_prob\": 0.1447686603256489, \"\\u03b2\": 0.0, \"effective_class_frequency\": 0.1}, {\"class_num\": 4, \"class_prob\": 0.08681283250040303, \"\\u03b2\": 0.0, \"effective_class_frequency\": 0.1}, {\"class_num\": 5, \"class_prob\": 0.05199097211026923, \"\\u03b2\": 0.0, \"effective_class_frequency\": 0.1}, {\"class_num\": 6, \"class_prob\": 0.031194583266161535, \"\\u03b2\": 0.0, \"effective_class_frequency\": 0.1}, {\"class_num\": 7, \"class_prob\": 0.01870062872803482, \"\\u03b2\": 0.0, \"effective_class_frequency\": 0.1}, {\"class_num\": 8, \"class_prob\": 0.011204256005158795, \"\\u03b2\": 0.0, \"effective_class_frequency\": 0.1}, {\"class_num\": 9, \"class_prob\": 0.006690311139771078, \"\\u03b2\": 0.0, \"effective_class_frequency\": 0.1}, {\"class_num\": 10, \"class_prob\": 0.004030307915524746, \"\\u03b2\": 0.0, \"effective_class_frequency\": 0.1}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot effective class probability for each class number for each β\n",
    "\n",
    "alt.Chart(data=df).mark_bar().encode(\n",
    "    x=alt.X(\"β:N\", title=None, axis=alt.Axis(ticks=False, labels=False), sort=βs),\n",
    "    y=alt.Y(\"effective_class_frequency\", title=\"Smoothed class probability\"),\n",
    "    color=alt.Color(\"β:N\", sort=βs),\n",
    "    column=alt.Column(\"class_num:O\", title=\"Classes (ranked by frequency)\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 1\n",
    "\n",
    "We get the final test accuracy for each of the approaches (baseline ERM, posthoc update and logit adjusted loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tensorboard_data(log_dir: str, exp_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns the logs from Tensorboard SummaryWriter in blob storage as a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        log_dir (str): the path to the Tensorboard logs\n",
    "        exp_name (str): name of the experiment\n",
    "    \"\"\"\n",
    "\n",
    "    event_acc = EventAccumulator(log_dir, size_guidance={TENSORS: 0})\n",
    "    event_acc.Reload()\n",
    "\n",
    "    data = []\n",
    "    tensors = event_acc.Tags()[\"tensors\"]\n",
    "\n",
    "    for tag in tensors:\n",
    "        events = event_acc.Tensors(tag)\n",
    "        steps = [event.step for event in events]\n",
    "        tensor_protos = [make_ndarray(event.tensor_proto).item() for event in events]\n",
    "        for step, tensor_proto in list(zip(steps, tensor_protos)):\n",
    "            data.append(\n",
    "                {\n",
    "                    \"experiment\": exp_name,\n",
    "                    \"metric\": tag,\n",
    "                    \"step\": step,\n",
    "                    \"value\": tensor_proto,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_exp_names = sorted(os.listdir(\"./log\"))  # the folder names\n",
    "exp_names = [\n",
    "    _exp_name.replace(\"_\", \" \") for _exp_name in _exp_names\n",
    "]  # remove underscore for space\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for _exp_name, exp_name in list(zip(_exp_names, exp_names)):\n",
    "    df = pd.concat(\n",
    "        [\n",
    "            df,\n",
    "            load_tensorboard_data(\n",
    "                log_dir=\"./log/\" + _exp_name + \"/test\", exp_name=exp_name\n",
    "            ),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Additive update</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.6971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Additive update</td>\n",
       "      <td>logit-adjusted accuracy</td>\n",
       "      <td>0.7645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ERM</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.6927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LA</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.7610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        experiment                   metric   value\n",
       "0  Additive update                 accuracy  0.6971\n",
       "1  Additive update  logit-adjusted accuracy  0.7645\n",
       "2              ERM                 accuracy  0.6927\n",
       "3               LA                 accuracy  0.7610"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_accuracy_df = df[df.step == 19200].reset_index().drop([\"index\", \"step\"], axis=1)\n",
    "final_accuracy_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
