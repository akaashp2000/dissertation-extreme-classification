{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import altair as alt\n",
    "\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch a TensorBoard Session in VS Code or...\n",
    "\n",
    "Run the below (you may have to run the second command twice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or use\n",
    "\n",
    "```\n",
    "!tensorboard --logdir log\n",
    "```\n",
    "if the above doesn't work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training (and evaluation)\n",
    "\n",
    "Use ```cifar_train.py``` to train on the imbalanced version of CIFAR 10. This is to get the results in Table 2.\n",
    "\n",
    "Call it with the following flags/parameters:\n",
    "\n",
    "* ```gpu```: ```0```\n",
    "* ```imb_type```: ```exp``` (means that the class frequency decays exponentially)\n",
    "* ```imb_factor```: ```0.01``` (the ratio of the lowest class frequency to the highest class frequency)\n",
    "* ```loss_type```:\n",
    "    * ```CE```: Cross Entropy Loss\n",
    "    * ```LogAdj```: Logit Adjusted Loss\n",
    "    * ```LDAM```: LDAM loss\n",
    "* ```train_rule``` (how/when to weight the loss):\n",
    "    * ```None```: default training. No weighting.\n",
    "    * ```Reweight```: weight the per-class loss multiplicatively by inverse effective frequency. Also requires beta argument.\n",
    "    * ```ClassWeight```: weight the per-class loss multiplicatively by inverse frequency, i.e. Reweight with $\\beta = 1$\n",
    "    * ```DRW```: delayed reweighting. Reweight the loss ONLY after 160th epoch. Also requires beta argument.\n",
    "    * ```DRW_ClassWeight```. Reweight the loss ONLY after 160th epoch, with $\\beta = 1$.\n",
    "* ```beta```: value of $\\beta$\n",
    "\n",
    "The results can be found in Tensorboard: the 'Best' value corresponds to the final \"test_top1_best\" and the 'Final' value, to the final \"test_val_top1\" value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cao et. al"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ERM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python cifar_train.py --gpu 0 --imb_type exp --imb_factor 0.01 --loss_type CE --train_rule None --exp_str \"01\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python cifar_train.py --gpu 0 --imb_type exp --imb_factor 0.01 --loss_type LDAM --train_rule None --exp_str \"02\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDAM+DRW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python cifar_train.py --gpu 0 --imb_type exp --imb_factor 0.01 --loss_type LDAM --train_rule DRW --beta 0.9999 --exp_str \"03\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cui et. al\n",
    "\n",
    "For $\\beta = 0.9, 0.99, 0.999, 0.9999$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python cifar_train.py --gpu 0 --imb_type exp --imb_factor 0.01 --loss_type CE --train_rule Reweight --beta 0.9999 --exp_str \"04\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python cifar_train.py --gpu 0 --imb_type exp --imb_factor 0.01 --loss_type CE --train_rule Reweight --beta 0.9990 --exp_str \"05\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python cifar_train.py --gpu 0 --imb_type exp --imb_factor 0.01 --loss_type CE --train_rule Reweight --beta 0.9900 --exp_str \"06\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python cifar_train.py --gpu 0 --imb_type exp --imb_factor 0.01 --loss_type CE --train_rule Reweight --beta 0.9000 --exp_str \"07\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\beta = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python cifar_train.py --gpu 0 --imb_type exp --imb_factor 0.01 --loss_type CE --train_rule ClassWeight --exp_str \"08\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDAM+DRW ($\\beta=1$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python cifar_train.py --gpu 0 --imb_type exp --imb_factor 0.01 --loss_type LDAM --train_rule DRW_ClassWeight --exp_str \"09\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logit Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python cifar_train.py --gpu 0 --imb_type exp --imb_factor 0.01 --loss_type LogAdj --train_rule None --exp_str \"10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logit Adjustment+DRW ($\\beta = 1$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python cifar_train.py --gpu 0 --imb_type exp --imb_factor 0.01 --loss_type LogAdj --train_rule DRW_ClassWeight --exp_str \"11\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the results\n",
    "\n",
    "* For Table 2, Figures 7, 8 and 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tensorboard_data(log_dir: str, print_scalars: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns the logs from Tensorboard SummaryWriter in blob storage as a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        log_dir (str): the path to the Tensorboard logs\n",
    "        print_scalars (bool): whether or not to print the list of scalars from the EventAccumulator. By default False (so doesn't print).\n",
    "    \"\"\"\n",
    "    event_acc = EventAccumulator(log_dir)\n",
    "    event_acc.Reload()\n",
    "\n",
    "    data = []\n",
    "    scalars = event_acc.Tags()[\"scalars\"]\n",
    "    if print_scalars:\n",
    "        print(scalars)\n",
    "\n",
    "    for tag in scalars:\n",
    "        events = event_acc.Scalars(tag)\n",
    "        steps = [event.step for event in events]\n",
    "        values = [event.value for event in events]\n",
    "        for step, value in list(zip(steps, values)):\n",
    "            data.append({\"tag\": tag, \"step\": step, \"value\": value})\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of dfs for each experiment\n",
    "\n",
    "exp_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we collect the results from each experiment from Tensorboard logs\n",
    "\n",
    "get_exp_no = lambda s: s.split(\"_\")[\n",
    "    -1\n",
    "]  # function to remove the '_{exp_no}' from the folder name\n",
    "\n",
    "_exp_names = sorted(\n",
    "    os.listdir(\"./log\"), key=get_exp_no\n",
    ")  # the folder names - sorted by experiment no,\n",
    "exp_names = [\n",
    "    \"_\".join(_exp_name.split(\"_\")[:-1])\n",
    "    .replace(\"cifar10_resnet32_\", \"\")\n",
    "    .replace(\"_exp_0.01\", \"\")\n",
    "    for _exp_name in _exp_names\n",
    "]\n",
    "# the experiment names but stripped of redundant info (since all models are cifar10, resnet32 with exp imbalance type and 0.01 imbal ratio)\n",
    "\n",
    "exp_nos = [\n",
    "    get_exp_no(_exp_name) for _exp_name in _exp_names\n",
    "]  # the experiment numbers that have logs\n",
    "\n",
    "for exp_no, _exp_name, exp_name in list(zip(exp_nos, _exp_names, exp_names)):\n",
    "    exp_dict[int(exp_no)] = load_tensorboard_data(\n",
    "        log_dir=\"./log/\" + _exp_name\n",
    "    )  # get the logs df for each experiment\n",
    "    exp_dict[int(exp_no)] = (\n",
    "        exp_dict[int(exp_no)].assign(exp_no=exp_no).assign(exp_name=exp_name)\n",
    "    )  # include a column for the experiment number and name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all the dfs\n",
    "\n",
    "whole_df = pd.concat([df for _, df in exp_dict.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    whole_df[whole_df.tag == \"acc/test_val_top1\"]\n",
    "    .sort_values([\"exp_no\", \"step\"])\n",
    "    .groupby([\"exp_no\", \"exp_name\"])\n",
    "    .agg({\"value\": [\"last\", \"max\"]})\n",
    "    .reset_index()\n",
    "    .drop([\"exp_no\"], axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Figure 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot different metrics across the experiments, using Altair\n",
    "\n",
    "exp_selector = alt.selection_point(fields=[\"exp_name\"], bind=\"legend\")\n",
    "\n",
    "for tag in [\"loss/train\", \"acc/train_top1\", \"acc/test_val_top1\"]:\n",
    "    (\n",
    "        alt.Chart(data=whole_df[whole_df.tag == tag])\n",
    "        .mark_line()\n",
    "        .encode(\n",
    "            x=\"step\",\n",
    "            y=alt.Y(\"value\", title=tag),\n",
    "            color=alt.Color(\"exp_name\"),\n",
    "            opacity=alt.condition(exp_selector, alt.value(1), alt.value(0)),\n",
    "        )\n",
    "        .add_params(exp_selector)\n",
    "        .properties(width=800, title=tag)\n",
    "    ).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figures 7 and 8: Per class accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of dfs for each experiment\n",
    "\n",
    "exp_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we collect the results from each experiment from Tensorboard logs\n",
    "\n",
    "get_exp_no = lambda s: s.split(\"_\")[\n",
    "    -1\n",
    "]  # function to remove the '_{exp_no}' from the folder name\n",
    "\n",
    "_exp_names = sorted(\n",
    "    os.listdir(\"./log\"), key=get_exp_no\n",
    ")  # the folder names - sorted by experiment no,\n",
    "exp_names = [\n",
    "    \"_\".join(_exp_name.split(\"_\")[:-1])\n",
    "    .replace(\"cifar10_resnet32_\", \"\")\n",
    "    .replace(\"_exp_0.01\", \"\")\n",
    "    for _exp_name in _exp_names\n",
    "]\n",
    "# the experiment names but stripped of redundant info (since all models are cifar10, resnet32 with exp imbalance type and 0.01 imbal ratio)\n",
    "\n",
    "exp_nos = [\n",
    "    get_exp_no(_exp_name) for _exp_name in _exp_names\n",
    "]  # the experiment numbers that have logs\n",
    "\n",
    "for exp_no, _exp_name, exp_name in list(zip(exp_nos, _exp_names, exp_names)):\n",
    "    exp_dict[int(exp_no)] = pd.DataFrame()\n",
    "    for class_num in range(10):\n",
    "        exp_dict[int(exp_no)] = pd.concat(\n",
    "            [\n",
    "                exp_dict[int(exp_no)],\n",
    "                load_tensorboard_data(\n",
    "                    log_dir=\"./log/\"\n",
    "                    + _exp_name\n",
    "                    + \"/acc/test_val_cls_acc/\"\n",
    "                    + str(class_num)\n",
    "                ).assign(class_num=class_num + 1),\n",
    "            ]\n",
    "        )  # get the logs df for each experiment\n",
    "        exp_dict[int(exp_no)] = (\n",
    "            exp_dict[int(exp_no)].assign(exp_no=exp_no).assign(exp_name=exp_name)\n",
    "        )  # include a column for the experiment number and name and class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all the dfs\n",
    "\n",
    "whole_df = pd.concat([df for _, df in exp_dict.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot final test accuracy\n",
    "\n",
    "exp_selector = alt.selection_point(fields=[\"exp_name\"], toggle=\"true\")\n",
    "\n",
    "tag = \"acc/test_val_cls_acc\"\n",
    "\n",
    "exp_chart = (\n",
    "    alt.Chart(data=whole_df[[\"exp_name\"]].drop_duplicates())\n",
    "    .mark_circle(filled=True, size=200)\n",
    "    .encode(\n",
    "        y=\"exp_name:N\",\n",
    "        color=\"exp_name:N\",\n",
    "        opacity=alt.condition(exp_selector, alt.value(1), alt.value(0.2)),\n",
    "    )\n",
    "    .add_params(exp_selector)\n",
    ")\n",
    "\n",
    "chart = (\n",
    "    alt.Chart(data=whole_df[(whole_df.tag == tag) & (whole_df.step == 199)])\n",
    "    .mark_bar()\n",
    "    .encode(\n",
    "        x=alt.X(\"exp_no:N\", title=None, axis=alt.Axis(ticks=False, labels=False)),\n",
    "        column=alt.Column(\"class_num:O\"),\n",
    "        y=alt.Y(\"value\", title=tag),\n",
    "        color=alt.Color(\"exp_name:N\", legend=None),\n",
    "    )\n",
    "    .transform_filter(exp_selector)\n",
    "    .add_params(exp_selector)\n",
    ")\n",
    "\n",
    "exp_chart | chart"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
